{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sashakapralov/Documents/GitHub/Mask_RCNN\n"
     ]
    }
   ],
   "source": [
    "print(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python36.zip',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python3.6',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python3.6/lib-dynload',\n",
       " '/Users/sashakapralov/.local/lib/python3.6/site-packages',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python3.6/site-packages',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/sashakapralov/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python36.zip',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python3.6',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python3.6/lib-dynload',\n",
       " '/Users/sashakapralov/.local/lib/python3.6/site-packages',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python3.6/site-packages',\n",
       " '/Users/sashakapralov/anaconda3/envs/py36_2/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/sashakapralov/.ipython',\n",
       " '/Users/sashakapralov/Documents/GitHub/Mask_RCNN']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce annotations JSON to annotated images and split into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../CV-to-Maps/water_tower_annotations.json\", \"r\") as jsonFile:\n",
    "    orig_data = json.load(jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_via_settings', '_via_img_metadata', '_via_attributes'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17696"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(orig_data['_via_img_metadata'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = list(orig_data['_via_img_metadata'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'filename': '00000001.jpg', 'size': 53855, 'regions': [], 'file_attributes': {}}, {'filename': '00000002.jpg', 'size': 39423, 'regions': [{'shape_attributes': {'name': 'polygon', 'all_points_x': [118, 139, 142, 165, 178, 209, 262, 309, 355, 409, 455, 494, 521, 552, 563, 553, 571], 'all_points_y': [463, 157, 132, 106, 101, 69, 47, 38, 36, 40, 54, 74, 97, 123, 153, 183, 466]}, 'region_attributes': {'name': 'water_tower'}}], 'file_attributes': {}}]\n"
     ]
    }
   ],
   "source": [
    "print(annotations[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = [a for a in annotations if a['regions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'filename': '00000002.jpg', 'size': 39423, 'regions': [{'shape_attributes': {'name': 'polygon', 'all_points_x': [118, 139, 142, 165, 178, 209, 262, 309, 355, 409, 455, 494, 521, 552, 563, 553, 571], 'all_points_y': [463, 157, 132, 106, 101, 69, 47, 38, 36, 40, 54, 74, 97, 123, 153, 183, 466]}, 'region_attributes': {'name': 'water_tower'}}], 'file_attributes': {}}, {'filename': '00000003.jpg', 'size': 24062, 'regions': [{'shape_attributes': {'name': 'polygon', 'all_points_x': [266, 273, 261, 253, 269, 274, 286, 285, 294, 324, 364, 417, 468, 523, 550, 573, 580, 584, 594, 595, 590, 596, 588, 582, 577, 549, 552, 542, 536, 526, 523, 482, 452, 452, 403, 403, 350, 350, 339, 337, 314, 311, 295, 301, 291, 287], 'all_points_y': [440, 351, 352, 340, 324, 308, 302, 270, 251, 227, 212, 205, 206, 222, 236, 258, 281, 305, 318, 343, 356, 500, 489, 484, 362, 395, 472, 469, 478, 476, 408, 422, 424, 511, 510, 421, 407, 436, 444, 402, 388, 446, 432, 379, 366, 453]}, 'region_attributes': {'name': 'water_tower'}}], 'file_attributes': {}}]\n"
     ]
    }
   ],
   "source": [
    "print(annotations[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'polygon', 'all_points_x': [118, 139, 142, 165, 178, 209, 262, 309, 355, 409, 455, 494, 521, 552, 563, 553, 571], 'all_points_y': [463, 157, 132, 106, 101, 69, 47, 38, 36, 40, 54, 74, 97, 123, 153, 183, 466]}]\n",
      "[{'name': 'polygon', 'all_points_x': [266, 273, 261, 253, 269, 274, 286, 285, 294, 324, 364, 417, 468, 523, 550, 573, 580, 584, 594, 595, 590, 596, 588, 582, 577, 549, 552, 542, 536, 526, 523, 482, 452, 452, 403, 403, 350, 350, 339, 337, 314, 311, 295, 301, 291, 287], 'all_points_y': [440, 351, 352, 340, 324, 308, 302, 270, 251, 227, 212, 205, 206, 222, 236, 258, 281, 305, 318, 343, 356, 500, 489, 484, 362, 395, 472, 469, 478, 476, 408, 422, 424, 511, 510, 421, 407, 436, 444, 402, 388, 446, 432, 379, 366, 453]}]\n"
     ]
    }
   ],
   "source": [
    "for a in annotations[:2]:\n",
    "    polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "    print(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find image files in the images directory that have regions defined and place them into train and val folders\n",
    "labeled_imgs = [img_dict['filename'] for img_dict in annotations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to shuffle and partition list into roughly equal n parts\n",
    "def partition (list_in, n):\n",
    "    random.shuffle(list_in)\n",
    "    return [list_in[i::n] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, val_imgs = partition(labeled_imgs,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 119 \n",
      "Number of validation images: 118\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train images:\",len(train_imgs),\"\\nNumber of validation images:\",len(val_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '../../../CV-to-Maps/water_tower/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../CV-to-Maps/water_tower/train'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(img_dir,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the train directory\n",
      "Successfully created the val directory\n"
     ]
    }
   ],
   "source": [
    "for folder in ['train','val']:\n",
    "    try:  \n",
    "        os.mkdir(os.path.join(img_dir,folder))\n",
    "    except OSError:  \n",
    "        print (\"Creation of the {} directory failed\".format(folder))\n",
    "    else:  \n",
    "        print (\"Successfully created the {} directory\".format(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move train set and validation set images into their respective directories\n",
    "for img in train_imgs:\n",
    "    os.rename(os.path.join(img_dir,img),os.path.join(img_dir,'train',img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in val_imgs:\n",
    "    os.rename(os.path.join(img_dir,img),os.path.join(img_dir,'val',img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {main_k: {k2: v2 for k2, v2 in main_v.items() if v2['filename'] in train_imgs} for main_k, main_v in orig_data.items() if main_k == '_via_img_metadata'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict_full = {}\n",
    "for k, v in orig_data.items():\n",
    "    if k == '_via_img_metadata':        \n",
    "        train_dict_full.update(train_dict)\n",
    "    else:\n",
    "        train_dict_full[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = {main_k: {k2: v2 for k2, v2 in main_v.items() if v2['filename'] in val_imgs} for main_k, main_v in orig_data.items() if main_k == '_via_img_metadata'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict_full = {}\n",
    "for k, v in orig_data.items():\n",
    "    if k == '_via_img_metadata':\n",
    "        val_dict_full.update(val_dict)\n",
    "    else:\n",
    "        val_dict_full[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store dictionaries in JSON files\n",
    "with open(\"train.json\", \"w\") as jsonFile:\n",
    "    json.dump(train_dict_full, jsonFile)\n",
    "    \n",
    "with open(\"val.json\", \"w\") as jsonFile:\n",
    "    json.dump(val_dict_full, jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TowerDataset(utils.Dataset):\n",
    "\n",
    "    def load_tower(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the Tower dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"tower\", 1, \"tower\")\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Load annotations\n",
    "        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
    "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "        #   'regions': {\n",
    "        #       '0': {\n",
    "        #           'region_attributes': {},\n",
    "        #           'shape_attributes': {\n",
    "        #               'all_points_x': [...],\n",
    "        #               'all_points_y': [...],\n",
    "        #               'name': 'polygon'}},\n",
    "        #       ... more regions ...\n",
    "        #   },\n",
    "        #   'size': 100202\n",
    "        # }\n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        # Note: In VIA 2.0, regions was changed from a dict to a list.\n",
    "        \n",
    "        orig_data = json.load(open(os.path.join(dataset_dir, \"water_tower_annotations.json\")))\n",
    "        annotations = list(orig_data['_via_img_metadata'].values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinaets of points of the polygons that make up\n",
    "            # the outline of each object instance. These are stores in the\n",
    "            # shape_attributes (see json format above)\n",
    "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
    "            if type(a['regions']) is dict:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "            else:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"tower\",\n",
    "                image_id=a['filename'],  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a tower dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"tower\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"tower\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
